{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "FLIiw_82gC0E"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0T0Ycv59if-D"
   },
   "source": [
    "### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "R2-zCWvgeV9N"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.tsv', delimiter = '\\t', quoting = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mueKqNaBgwR5",
    "outputId": "34b8bb83-9177-4828-d37b-baecf956a6a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 4)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2u43Iagaja_V",
    "outputId": "4f1fa52a-8d2b-4665-e953-e267bbf5cd9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId      0\n",
       "SentenceId    0\n",
       "Phrase        0\n",
       "Sentiment     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ytWNK_wqjdqk",
    "outputId": "38a3d1e3-04ea-4f18-d60c-273d6f053f92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 0], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "U0YPyz7vgyFj",
    "outputId": "b2e4dafb-ebc8-462e-eb71-026b7ffe789f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poBNyvYWibTX"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5EvqLWlLg0Ho",
    "outputId": "43b86c33-7207-47b4-e3f4-49a7db1b33f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zianz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "all_stopwords = stopwords.words('english')\n",
    "all_stopwords.remove('not')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wP0WzMpEj9oN"
   },
   "source": [
    "Remove all special and numeric character from data and also remove stopwards and apply stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "JgZoFbZrhOg3"
   },
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "\n",
    "for i in range(0, df.shape[0]):\n",
    "  review = re.sub('[^a-zA-Z]', ' ', df['Phrase'][i])\n",
    "  review = review.lower()\n",
    "  review = review.split()\n",
    "  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "  review = ' '.join(review)\n",
    "  corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8d6gxbxsiGGb",
    "outputId": "eb2639fb-30f9-4381-89cd-b614a6b4ce88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seri escapad demonstr adag good goos also good gander occasion amus none amount much stori',\n",
       " 'seri escapad demonstr adag good goos',\n",
       " 'seri',\n",
       " '',\n",
       " 'seri',\n",
       " 'escapad demonstr adag good goos',\n",
       " '',\n",
       " 'escapad demonstr adag good goos',\n",
       " 'escapad',\n",
       " 'demonstr adag good goos',\n",
       " 'demonstr adag',\n",
       " 'demonstr',\n",
       " 'adag',\n",
       " '',\n",
       " 'adag',\n",
       " 'good goos',\n",
       " '',\n",
       " 'good goos',\n",
       " '',\n",
       " 'good goos',\n",
       " '',\n",
       " 'good goos',\n",
       " 'good',\n",
       " 'goos',\n",
       " '',\n",
       " 'goos',\n",
       " 'goos',\n",
       " 'also good gander occasion amus none amount much stori',\n",
       " 'also good gander occasion amus none amount much stori',\n",
       " 'also',\n",
       " 'also',\n",
       " 'good gander occasion amus none amount much stori',\n",
       " 'gander occasion amus none amount much stori',\n",
       " 'gander occasion amus none amount much stori',\n",
       " 'gander',\n",
       " 'gander',\n",
       " 'gander',\n",
       " '',\n",
       " 'occasion amus none amount much stori',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'occasion amus none amount much stori',\n",
       " 'occasion',\n",
       " 'amus none amount much stori',\n",
       " 'amus',\n",
       " 'none amount much stori',\n",
       " '',\n",
       " 'none amount much stori',\n",
       " 'none',\n",
       " 'amount much stori',\n",
       " 'amount much stori',\n",
       " 'amount much stori',\n",
       " 'amount',\n",
       " 'much stori',\n",
       " '',\n",
       " 'much stori',\n",
       " 'much',\n",
       " 'stori',\n",
       " 'stori',\n",
       " 'stori',\n",
       " '',\n",
       " 'quiet introspect entertain independ worth seek',\n",
       " 'quiet introspect entertain independ',\n",
       " '',\n",
       " 'quiet introspect entertain independ',\n",
       " 'quiet introspect entertain',\n",
       " 'quiet',\n",
       " 'introspect entertain',\n",
       " 'introspect entertain',\n",
       " 'introspect',\n",
       " 'introspect',\n",
       " '',\n",
       " 'entertain',\n",
       " 'independ',\n",
       " 'worth seek',\n",
       " 'worth seek',\n",
       " 'worth',\n",
       " 'worth',\n",
       " 'seek',\n",
       " 'even fan ismail merchant work suspect would hard time sit one',\n",
       " 'even fan ismail merchant work',\n",
       " 'even fan',\n",
       " 'even',\n",
       " 'fan',\n",
       " 'ismail merchant work',\n",
       " 'ismail merchant work',\n",
       " 'ismail merchant',\n",
       " 'ismail',\n",
       " 'merchant',\n",
       " 'merchant',\n",
       " '',\n",
       " 'work',\n",
       " 'suspect would hard time sit one',\n",
       " 'suspect',\n",
       " 'suspect',\n",
       " 'suspect',\n",
       " '',\n",
       " 'suspect',\n",
       " 'would hard time sit one',\n",
       " 'would hard time sit one',\n",
       " 'would',\n",
       " 'hard time sit one',\n",
       " '',\n",
       " 'hard time sit one',\n",
       " 'hard time',\n",
       " 'hard time',\n",
       " 'hard',\n",
       " 'time',\n",
       " 'sit one',\n",
       " 'sit',\n",
       " 'one',\n",
       " '',\n",
       " 'one',\n",
       " 'one',\n",
       " 'posit thrill combin ethnographi intrigu betray deceit murder shakespearean tragedi juici soap opera',\n",
       " 'posit thrill combin ethnographi intrigu betray deceit murder shakespearean tragedi juici soap opera',\n",
       " 'posit thrill combin ethnographi intrigu betray deceit murder',\n",
       " 'posit thrill combin',\n",
       " 'posit thrill combin',\n",
       " 'posit',\n",
       " 'thrill combin',\n",
       " 'thrill',\n",
       " 'combin',\n",
       " 'ethnographi intrigu betray deceit murder',\n",
       " 'ethnographi intrigu betray deceit murder',\n",
       " 'ethnographi',\n",
       " 'ethnographi',\n",
       " 'intrigu betray deceit murder',\n",
       " '',\n",
       " 'intrigu betray deceit murder',\n",
       " 'intrigu betray deceit murder',\n",
       " 'intrigu',\n",
       " 'betray deceit murder',\n",
       " 'betray deceit murder',\n",
       " 'betray',\n",
       " 'deceit murder',\n",
       " 'deceit murder',\n",
       " 'deceit',\n",
       " 'deceit',\n",
       " 'murder',\n",
       " 'shakespearean tragedi juici soap opera',\n",
       " 'shakespearean tragedi juici soap opera',\n",
       " 'shakespearean tragedi',\n",
       " 'shakespearean tragedi',\n",
       " 'shakespearean tragedi',\n",
       " 'shakespearean',\n",
       " 'tragedi',\n",
       " '',\n",
       " 'juici soap opera',\n",
       " 'juici soap opera',\n",
       " 'juici',\n",
       " 'soap opera',\n",
       " 'soap',\n",
       " 'opera',\n",
       " 'aggress self glorif manipul whitewash',\n",
       " 'aggress self glorif manipul whitewash',\n",
       " 'aggress',\n",
       " 'self glorif manipul whitewash',\n",
       " 'self glorif',\n",
       " 'self glorif',\n",
       " 'manipul whitewash',\n",
       " 'manipul whitewash',\n",
       " 'manipul',\n",
       " 'whitewash',\n",
       " 'comedi drama nearli epic proport root sincer perform titl charact undergo midlif crisi',\n",
       " 'comedi drama nearli epic proport',\n",
       " 'comedi drama',\n",
       " 'comedi drama',\n",
       " 'nearli epic proport',\n",
       " 'nearli epic proport',\n",
       " 'nearli epic',\n",
       " 'nearli',\n",
       " 'epic',\n",
       " 'proport',\n",
       " 'root sincer perform titl charact undergo midlif crisi',\n",
       " 'root sincer perform titl charact undergo midlif crisi',\n",
       " 'root sincer perform',\n",
       " 'root',\n",
       " 'sincer perform',\n",
       " '',\n",
       " 'sincer perform',\n",
       " 'sincer perform',\n",
       " 'sincer',\n",
       " 'perform',\n",
       " 'titl charact undergo midlif crisi',\n",
       " '',\n",
       " 'titl charact undergo midlif crisi',\n",
       " 'titl charact',\n",
       " 'titl charact',\n",
       " 'titl',\n",
       " 'charact',\n",
       " 'undergo midlif crisi',\n",
       " 'undergo',\n",
       " 'midlif crisi',\n",
       " 'midlif',\n",
       " 'crisi',\n",
       " 'narr troubl everi day plod mess',\n",
       " 'narr',\n",
       " 'troubl everi day plod mess',\n",
       " 'troubl everi day plod mess',\n",
       " 'troubl everi day',\n",
       " 'troubl',\n",
       " 'everi day',\n",
       " 'everi',\n",
       " 'day',\n",
       " 'plod mess',\n",
       " 'plod mess',\n",
       " 'plod mess',\n",
       " 'plod mess',\n",
       " 'plod',\n",
       " 'mess',\n",
       " 'import earnest thick wit play like read bartlett familiar quotat',\n",
       " 'import',\n",
       " 'import',\n",
       " 'earnest thick wit play like read bartlett familiar quotat',\n",
       " 'earnest thick wit play like read bartlett familiar quotat',\n",
       " '',\n",
       " 'earnest thick wit play like read bartlett familiar quotat',\n",
       " 'earnest',\n",
       " 'earnest',\n",
       " 'thick wit play like read bartlett familiar quotat',\n",
       " '',\n",
       " 'thick wit play like read bartlett familiar quotat',\n",
       " 'thick',\n",
       " 'wit play like read bartlett familiar quotat',\n",
       " '',\n",
       " 'wit play like read bartlett familiar quotat',\n",
       " 'wit',\n",
       " 'play like read bartlett familiar quotat',\n",
       " '',\n",
       " 'play like read bartlett familiar quotat',\n",
       " 'play',\n",
       " 'like read bartlett familiar quotat',\n",
       " 'like',\n",
       " 'read bartlett familiar quotat',\n",
       " 'read',\n",
       " 'read',\n",
       " 'bartlett familiar quotat',\n",
       " '',\n",
       " 'bartlett familiar quotat',\n",
       " 'bartlett',\n",
       " 'bartlett',\n",
       " 'familiar quotat',\n",
       " 'familiar',\n",
       " 'quotat',\n",
       " 'n leav much',\n",
       " 'n leav much',\n",
       " 'n leav much',\n",
       " 'n leav much',\n",
       " 'n',\n",
       " '',\n",
       " 'n',\n",
       " 'leav much',\n",
       " 'leav',\n",
       " 'leav',\n",
       " '',\n",
       " 'much',\n",
       " 'could hate reason',\n",
       " 'could hate reason',\n",
       " 'could hate reason',\n",
       " 'could',\n",
       " 'hate reason',\n",
       " 'hate',\n",
       " 'hate',\n",
       " 'reason',\n",
       " 'reason',\n",
       " 'reason',\n",
       " '',\n",
       " 'reason',\n",
       " 'littl recommend snow dog unless one consid clich dialogu pervers escap sourc high hilar',\n",
       " '',\n",
       " 'littl recommend snow dog unless one consid clich dialogu pervers escap sourc high hilar',\n",
       " 'littl recommend snow dog unless one consid clich dialogu pervers escap sourc high hilar',\n",
       " 'littl recommend snow dog',\n",
       " 'littl recommend snow dog',\n",
       " 'littl recommend snow dog',\n",
       " 'littl',\n",
       " 'recommend snow dog',\n",
       " 'recommend snow dog',\n",
       " 'recommend',\n",
       " 'snow dog',\n",
       " 'snow',\n",
       " 'dog',\n",
       " 'unless one consid clich dialogu pervers escap sourc high hilar',\n",
       " 'unless',\n",
       " 'one consid clich dialogu pervers escap sourc high hilar',\n",
       " 'consid clich dialogu pervers escap sourc high hilar',\n",
       " 'consid',\n",
       " 'clich dialogu pervers escap sourc high hilar',\n",
       " 'clich dialogu pervers escap',\n",
       " 'clich dialogu',\n",
       " 'clich dialogu',\n",
       " 'clich',\n",
       " 'dialogu',\n",
       " 'pervers escap',\n",
       " 'pervers',\n",
       " 'escap',\n",
       " 'sourc high hilar',\n",
       " 'sourc',\n",
       " 'sourc',\n",
       " 'high hilar',\n",
       " 'high hilar',\n",
       " 'high',\n",
       " 'hilar',\n",
       " 'kung pow oedekerk realiz childhood dream martial art flick prove sometim dream youth remain',\n",
       " 'kung pow',\n",
       " 'kung',\n",
       " 'pow',\n",
       " 'oedekerk realiz childhood dream martial art flick prove sometim dream youth remain',\n",
       " 'oedekerk realiz childhood dream martial art flick prove sometim dream youth remain',\n",
       " 'oedekerk realiz childhood dream martial art flick',\n",
       " 'oedekerk realiz childhood dream martial art flick',\n",
       " 'oedekerk realiz childhood dream martial art flick',\n",
       " 'oedekerk realiz childhood dream martial art flick',\n",
       " 'oedekerk realiz childhood dream',\n",
       " 'oedekerk realiz',\n",
       " 'oedekerk',\n",
       " 'oedekerk',\n",
       " 'realiz',\n",
       " 'childhood dream',\n",
       " 'childhood dream',\n",
       " '',\n",
       " 'childhood dream',\n",
       " 'childhood',\n",
       " 'dream',\n",
       " 'martial art flick',\n",
       " 'martial art flick',\n",
       " '',\n",
       " 'martial art flick',\n",
       " 'martial art flick',\n",
       " 'martial art flick',\n",
       " 'martial art',\n",
       " 'flick',\n",
       " 'prove sometim dream youth remain',\n",
       " 'prove',\n",
       " 'sometim dream youth remain',\n",
       " 'sometim dream youth remain',\n",
       " 'sometim',\n",
       " 'dream youth remain',\n",
       " 'dream youth',\n",
       " 'dream',\n",
       " 'dream',\n",
       " 'youth',\n",
       " 'youth',\n",
       " 'remain',\n",
       " '',\n",
       " 'remain',\n",
       " 'remain',\n",
       " '',\n",
       " '',\n",
       " 'perform absolut joy',\n",
       " 'perform',\n",
       " 'perform',\n",
       " 'absolut joy',\n",
       " 'absolut joy',\n",
       " '',\n",
       " 'absolut joy',\n",
       " '',\n",
       " 'absolut joy',\n",
       " 'absolut',\n",
       " 'joy',\n",
       " 'fresnadillo someth seriou say way extravag chanc distort perspect throw us path good sens',\n",
       " 'fresnadillo',\n",
       " 'someth seriou say way extravag chanc distort perspect throw us path good sens',\n",
       " 'someth seriou say way extravag chanc distort perspect throw us path good sens',\n",
       " '',\n",
       " 'someth seriou say way extravag chanc distort perspect throw us path good sens',\n",
       " 'someth',\n",
       " 'seriou say way extravag chanc distort perspect throw us path good sens',\n",
       " 'seriou',\n",
       " 'say way extravag chanc distort perspect throw us path good sens',\n",
       " 'say way extravag chanc distort perspect throw us path good sens',\n",
       " 'say',\n",
       " 'way extravag chanc distort perspect throw us path good sens',\n",
       " '',\n",
       " 'way extravag chanc distort perspect throw us path good sens',\n",
       " 'way',\n",
       " 'way',\n",
       " 'extravag chanc distort perspect throw us path good sens',\n",
       " '',\n",
       " 'extravag chanc distort perspect throw us path good sens',\n",
       " 'extravag chanc',\n",
       " 'extravag',\n",
       " 'chanc',\n",
       " 'distort perspect throw us path good sens',\n",
       " '',\n",
       " 'distort perspect throw us path good sens',\n",
       " 'distort perspect',\n",
       " 'distort perspect',\n",
       " 'distort',\n",
       " 'perspect',\n",
       " '',\n",
       " 'perspect',\n",
       " 'throw us path good sens',\n",
       " 'throw us',\n",
       " 'throw',\n",
       " 'us',\n",
       " 'path good sens',\n",
       " '',\n",
       " 'path good sens',\n",
       " 'path',\n",
       " 'path',\n",
       " 'good sens',\n",
       " 'good sens',\n",
       " 'sens',\n",
       " 'still like moonlight mile better judgment damn',\n",
       " 'still like moonlight mile better judgment damn',\n",
       " 'still',\n",
       " 'like moonlight mile better judgment damn',\n",
       " 'like moonlight mile better judgment damn',\n",
       " 'moonlight mile better judgment damn',\n",
       " 'moonlight mile better judgment',\n",
       " 'moonlight',\n",
       " 'mile better judgment',\n",
       " 'mile',\n",
       " 'better judgment',\n",
       " 'better judgment',\n",
       " 'better',\n",
       " 'judgment',\n",
       " 'damn',\n",
       " 'damn',\n",
       " 'welcom relief basebal movi tri hard mythic one sweet modest ultim win stori',\n",
       " 'welcom relief basebal movi tri hard mythic',\n",
       " 'welcom relief',\n",
       " 'welcom relief',\n",
       " 'welcom',\n",
       " 'relief',\n",
       " 'basebal movi tri hard mythic',\n",
       " 'basebal movi tri hard mythic',\n",
       " 'basebal movi',\n",
       " 'basebal',\n",
       " 'movi',\n",
       " 'tri hard mythic',\n",
       " 'tri hard mythic',\n",
       " 'tri',\n",
       " 'hard mythic',\n",
       " '',\n",
       " 'hard mythic',\n",
       " 'mythic',\n",
       " 'mythic',\n",
       " 'mythic',\n",
       " 'one sweet modest ultim win stori',\n",
       " 'one sweet modest ultim win stori',\n",
       " 'sweet modest ultim win stori',\n",
       " 'sweet modest ultim win stori',\n",
       " 'sweet modest ultim win stori',\n",
       " 'sweet modest',\n",
       " 'sweet modest',\n",
       " 'sweet modest',\n",
       " 'sweet',\n",
       " 'sweet',\n",
       " 'modest',\n",
       " 'ultim win stori',\n",
       " 'ultim',\n",
       " 'win stori',\n",
       " 'win',\n",
       " 'bilingu charmer like woman inspir',\n",
       " 'bilingu charmer',\n",
       " 'bilingu charmer',\n",
       " 'bilingu charmer',\n",
       " 'bilingu',\n",
       " 'charmer',\n",
       " 'like woman inspir',\n",
       " 'like woman inspir',\n",
       " 'woman inspir',\n",
       " 'woman',\n",
       " 'woman',\n",
       " 'inspir',\n",
       " '',\n",
       " 'inspir',\n",
       " 'inspir',\n",
       " 'like less dizzili gorgeou companion mr wong mood love much hong kong movi despit mainland set',\n",
       " 'like less dizzili gorgeou companion mr',\n",
       " 'less dizzili gorgeou companion mr',\n",
       " 'less dizzili gorgeou companion',\n",
       " 'less dizzili gorgeou companion',\n",
       " 'less dizzili gorgeou',\n",
       " 'less',\n",
       " 'dizzili gorgeou',\n",
       " 'dizzili',\n",
       " 'gorgeou',\n",
       " 'companion',\n",
       " 'mr',\n",
       " 'mr',\n",
       " 'wong mood love much hong kong movi despit mainland set',\n",
       " 'wong',\n",
       " 'mood love much hong kong movi despit mainland set',\n",
       " 'mood love much hong kong movi despit mainland set',\n",
       " 'mood love much hong kong movi',\n",
       " 'mood love much hong kong movi',\n",
       " 'mood love much hong kong movi',\n",
       " 'mood',\n",
       " 'mood',\n",
       " 'love much hong kong movi',\n",
       " 'love much hong kong movi',\n",
       " 'love much',\n",
       " 'love',\n",
       " 'love',\n",
       " '',\n",
       " 'much',\n",
       " '',\n",
       " 'hong kong movi',\n",
       " 'hong kong movi',\n",
       " 'hong',\n",
       " 'kong movi',\n",
       " 'kong',\n",
       " 'movi',\n",
       " 'despit mainland set',\n",
       " 'despit',\n",
       " 'mainland set',\n",
       " '',\n",
       " 'mainland set',\n",
       " 'mainland',\n",
       " 'set',\n",
       " 'inept big screen remak aveng wild wild west',\n",
       " 'inept big screen remak aveng wild wild west',\n",
       " 'inept',\n",
       " '',\n",
       " 'inept',\n",
       " 'big screen remak aveng wild wild west',\n",
       " 'big screen remak aveng wild wild west',\n",
       " 'big screen remak',\n",
       " 'big screen',\n",
       " 'remak',\n",
       " 'aveng wild wild west',\n",
       " 'aveng wild wild west',\n",
       " 'aveng',\n",
       " 'aveng',\n",
       " 'aveng',\n",
       " 'wild wild west',\n",
       " 'wild wild west',\n",
       " 'wild',\n",
       " 'wild west',\n",
       " 'west',\n",
       " 'everyth expect noth',\n",
       " 'everyth expect noth',\n",
       " 'everyth expect noth',\n",
       " 'everyth expect noth',\n",
       " 'everyth',\n",
       " 'expect noth',\n",
       " 'expect noth',\n",
       " '',\n",
       " 'expect noth',\n",
       " 'expect noth',\n",
       " 'expect',\n",
       " 'expect',\n",
       " 'noth',\n",
       " 'noth',\n",
       " '',\n",
       " 'best indi year far',\n",
       " 'best',\n",
       " 'indi year far',\n",
       " 'indi year far',\n",
       " 'indi year',\n",
       " 'indi year',\n",
       " 'indi',\n",
       " 'year',\n",
       " 'year',\n",
       " 'year',\n",
       " 'far',\n",
       " 'far',\n",
       " 'hatfield hick make oddest coupl sens movi becom studi gambl publish world offer case studi exist apart movi polit ramif',\n",
       " 'hatfield hick make oddest coupl sens movi becom studi gambl publish world offer case studi exist apart movi polit ramif',\n",
       " 'hatfield hick make oddest coupl',\n",
       " 'hatfield hick make oddest coupl',\n",
       " 'hatfield hick make oddest coupl',\n",
       " 'hatfield hick',\n",
       " 'hatfield',\n",
       " 'hatfield',\n",
       " 'hick',\n",
       " 'make oddest coupl',\n",
       " 'make',\n",
       " 'oddest coupl',\n",
       " 'oddest',\n",
       " 'oddest',\n",
       " 'coupl',\n",
       " 'coupl',\n",
       " 'sens movi becom studi gambl publish world offer case studi exist apart movi polit ramif',\n",
       " 'sens',\n",
       " 'sens',\n",
       " 'movi becom studi gambl publish world offer case studi exist apart movi polit ramif',\n",
       " 'movi',\n",
       " 'becom studi gambl publish world offer case studi exist apart movi polit ramif',\n",
       " 'becom studi gambl publish world',\n",
       " 'becom studi gambl publish world',\n",
       " 'becom',\n",
       " 'studi gambl publish world',\n",
       " 'studi',\n",
       " 'studi',\n",
       " 'gambl publish world',\n",
       " 'gambl publish world',\n",
       " 'gambl',\n",
       " 'gambl',\n",
       " 'publish world',\n",
       " 'publish world',\n",
       " 'publish world',\n",
       " 'publish',\n",
       " 'world',\n",
       " 'offer case studi exist apart movi polit ramif',\n",
       " 'offer',\n",
       " 'case studi exist apart movi polit ramif',\n",
       " 'case studi',\n",
       " 'case studi',\n",
       " 'case',\n",
       " 'exist apart movi polit ramif',\n",
       " 'exist apart movi polit ramif',\n",
       " 'exist apart',\n",
       " 'exist',\n",
       " 'apart',\n",
       " 'movi polit ramif',\n",
       " 'movi polit ramif',\n",
       " 'movi polit ramif',\n",
       " 'movi',\n",
       " 'movi',\n",
       " 'polit ramif',\n",
       " 'polit',\n",
       " 'ramif',\n",
       " 'like go hous parti watch host defend froth ex girlfriend',\n",
       " 'like go hous parti watch host defend froth ex girlfriend',\n",
       " 'like go hous parti watch host defend froth ex girlfriend',\n",
       " 'like go hous parti watch host defend froth ex girlfriend',\n",
       " 'go hous parti watch host defend froth ex girlfriend',\n",
       " 'go hous parti',\n",
       " 'go hous parti',\n",
       " 'go',\n",
       " 'hous parti',\n",
       " 'hous parti',\n",
       " 'hous parti',\n",
       " 'hous',\n",
       " 'parti',\n",
       " 'watch host defend froth ex girlfriend',\n",
       " 'watch',\n",
       " 'host defend froth ex girlfriend',\n",
       " 'host',\n",
       " 'host',\n",
       " 'defend froth ex girlfriend',\n",
       " 'defend',\n",
       " 'defend',\n",
       " '',\n",
       " 'froth ex girlfriend',\n",
       " '',\n",
       " 'froth ex girlfriend',\n",
       " 'froth ex girlfriend',\n",
       " 'froth',\n",
       " 'ex girlfriend',\n",
       " 'chuck norri grenad gag occur time windtalk good indic seriou mind film',\n",
       " 'chuck norri grenad gag',\n",
       " 'chuck norri grenad gag',\n",
       " 'chuck norri grenad gag',\n",
       " 'chuck',\n",
       " 'norri grenad gag',\n",
       " 'norri',\n",
       " 'grenad gag',\n",
       " '',\n",
       " 'grenad gag',\n",
       " 'grenad',\n",
       " 'gag',\n",
       " 'gag',\n",
       " '',\n",
       " 'occur time windtalk good indic seriou mind film',\n",
       " 'occur time windtalk good indic seriou mind film',\n",
       " 'occur',\n",
       " 'time windtalk good indic seriou mind film',\n",
       " 'time windtalk',\n",
       " 'time',\n",
       " 'time',\n",
       " '',\n",
       " 'time',\n",
       " 'windtalk',\n",
       " '',\n",
       " 'windtalk',\n",
       " 'good indic seriou mind film',\n",
       " 'good indic seriou mind film',\n",
       " 'good indic',\n",
       " 'good indic',\n",
       " 'indic',\n",
       " 'seriou mind film',\n",
       " 'seriou mind film',\n",
       " '',\n",
       " 'seriou mind film',\n",
       " 'seriou mind film',\n",
       " 'seriou mind',\n",
       " 'film',\n",
       " 'film',\n",
       " 'plot romant comedi boilerpl start finish',\n",
       " 'plot',\n",
       " 'plot',\n",
       " 'romant comedi boilerpl start finish',\n",
       " 'romant comedi boilerpl start finish',\n",
       " 'romant comedi boilerpl start finish',\n",
       " 'romant comedi boilerpl start',\n",
       " 'romant comedi boilerpl',\n",
       " 'romant',\n",
       " 'comedi boilerpl',\n",
       " 'comedi',\n",
       " 'boilerpl',\n",
       " 'start',\n",
       " 'start',\n",
       " 'finish',\n",
       " 'finish',\n",
       " 'arriv impecc pedigre mongrel pep almost indecipher plot complic',\n",
       " 'arriv impecc pedigre mongrel pep almost indecipher plot complic',\n",
       " 'arriv impecc pedigre mongrel pep almost indecipher plot complic',\n",
       " 'arriv',\n",
       " 'impecc pedigre mongrel pep almost indecipher plot complic',\n",
       " 'impecc pedigre mongrel pep almost indecipher plot complic',\n",
       " 'impecc pedigre mongrel pep almost',\n",
       " 'impecc pedigre mongrel pep',\n",
       " 'impecc pedigre mongrel pep',\n",
       " 'impecc pedigre mongrel pep',\n",
       " 'impecc pedigre mongrel pep',\n",
       " 'impecc',\n",
       " 'pedigre mongrel pep',\n",
       " 'pedigre',\n",
       " 'mongrel pep',\n",
       " 'mongrel pep',\n",
       " 'mongrel',\n",
       " 'pep',\n",
       " 'almost',\n",
       " 'indecipher plot complic',\n",
       " 'indecipher',\n",
       " 'plot complic',\n",
       " 'complic',\n",
       " 'film clearli mean preach exclus convert',\n",
       " 'film clearli mean',\n",
       " 'film',\n",
       " 'clearli mean',\n",
       " 'clearli mean',\n",
       " 'clearli',\n",
       " 'mean',\n",
       " 'mean',\n",
       " 'preach exclus convert',\n",
       " 'preach exclus convert',\n",
       " 'preach exclus',\n",
       " 'preach',\n",
       " 'exclus',\n",
       " 'convert',\n",
       " 'convert',\n",
       " 'convert',\n",
       " 'import earnest offer opportun occasion smile chuckl n give us reason theater beyond wild wit actor perform',\n",
       " 'import earnest offer opportun occasion smile chuckl',\n",
       " '',\n",
       " 'import earnest offer opportun occasion smile chuckl',\n",
       " 'import earnest',\n",
       " 'earnest',\n",
       " 'earnest',\n",
       " 'offer opportun occasion smile chuckl',\n",
       " 'offer opportun occasion smile',\n",
       " 'offer opportun occasion smile',\n",
       " 'offer',\n",
       " 'opportun occasion smile',\n",
       " 'opportun',\n",
       " 'occasion smile',\n",
       " 'occasion smile',\n",
       " 'occasion',\n",
       " 'smile',\n",
       " 'chuckl',\n",
       " 'n give us reason theater beyond wild wit actor perform',\n",
       " 'n give us reason theater beyond wild wit actor perform',\n",
       " 'n give us reason theater beyond wild wit actor perform',\n",
       " 'n give us reason theater beyond wild wit actor perform',\n",
       " 'give us reason theater beyond wild wit actor perform',\n",
       " 'give us',\n",
       " 'give',\n",
       " 'reason theater beyond wild wit actor perform',\n",
       " 'reason theater beyond wild wit actor perform',\n",
       " 'theater beyond wild wit actor perform',\n",
       " 'theater beyond wild wit actor perform',\n",
       " 'theater',\n",
       " 'theater',\n",
       " 'theater',\n",
       " 'theater',\n",
       " 'beyond wild wit actor perform',\n",
       " 'beyond',\n",
       " 'wild wit actor perform',\n",
       " 'wild wit',\n",
       " 'wild wit',\n",
       " 'wild',\n",
       " 'wild',\n",
       " 'actor perform',\n",
       " 'actor',\n",
       " 'actor',\n",
       " 'actor',\n",
       " '',\n",
       " 'latest vapid actor exercis appropri structur arthur schnitzler reigen',\n",
       " 'latest',\n",
       " 'latest',\n",
       " 'vapid actor exercis appropri structur arthur schnitzler reigen',\n",
       " 'vapid actor exercis appropri structur arthur schnitzler reigen',\n",
       " 'vapid actor exercis',\n",
       " 'vapid',\n",
       " 'actor exercis',\n",
       " 'actor',\n",
       " 'actor',\n",
       " 'exercis',\n",
       " 'appropri structur arthur schnitzler reigen',\n",
       " 'appropri structur arthur schnitzler reigen',\n",
       " 'appropri structur',\n",
       " 'appropri',\n",
       " 'structur',\n",
       " 'structur',\n",
       " 'arthur schnitzler reigen',\n",
       " 'arthur schnitzler reigen',\n",
       " 'arthur schnitzler',\n",
       " 'arthur',\n",
       " 'schnitzler',\n",
       " 'schnitzler',\n",
       " 'reigen',\n",
       " 'vaudevil show well construct narr term inoffens actual rather sweet',\n",
       " 'vaudevil show well construct narr term inoffens actual rather sweet',\n",
       " 'vaudevil show well construct narr',\n",
       " 'vaudevil show well construct narr',\n",
       " 'vaudevil show well construct narr',\n",
       " 'vaudevil',\n",
       " 'vaudevil',\n",
       " 'show well construct narr',\n",
       " 'show',\n",
       " 'well construct narr',\n",
       " '',\n",
       " 'well construct narr',\n",
       " 'well construct',\n",
       " 'narr',\n",
       " 'term inoffens actual rather sweet',\n",
       " 'term',\n",
       " '',\n",
       " 'term',\n",
       " '',\n",
       " 'term',\n",
       " 'inoffens actual rather sweet',\n",
       " 'inoffens actual rather sweet',\n",
       " 'inoffens actual rather sweet',\n",
       " 'inoffens actual',\n",
       " 'inoffens',\n",
       " 'inoffens',\n",
       " 'actual',\n",
       " 'rather sweet',\n",
       " 'rather',\n",
       " 'noth run mill action flick',\n",
       " 'run mill action flick',\n",
       " 'run mill action',\n",
       " 'run mill action',\n",
       " 'run mill action',\n",
       " 'run mill action',\n",
       " 'run mill',\n",
       " 'action',\n",
       " 'flick',\n",
       " 'hamper paralyz self indulg script aim poetri end sound like satir',\n",
       " 'hamper paralyz self indulg script aim poetri end sound like satir',\n",
       " 'hamper paralyz self indulg script',\n",
       " 'hamper paralyz self indulg script',\n",
       " 'hamper paralyz',\n",
       " 'hamper',\n",
       " 'paralyz',\n",
       " 'paralyz',\n",
       " 'paralyz',\n",
       " '',\n",
       " 'paralyz',\n",
       " 'paralyz',\n",
       " 'self indulg script',\n",
       " 'self indulg script',\n",
       " 'self indulg script',\n",
       " 'self indulg',\n",
       " 'script',\n",
       " '',\n",
       " 'aim poetri end sound like satir',\n",
       " 'aim poetri end sound like satir',\n",
       " 'aim poetri',\n",
       " 'aim poetri',\n",
       " 'aim',\n",
       " 'poetri',\n",
       " 'poetri',\n",
       " 'end sound like satir',\n",
       " 'end',\n",
       " 'end',\n",
       " '',\n",
       " 'sound like satir',\n",
       " 'sound',\n",
       " 'like satir',\n",
       " 'satir',\n",
       " 'ice age first comput gener featur cartoon feel like movi make glacial pace earli',\n",
       " 'ice age first comput gener featur cartoon feel like movi make glacial pace earli',\n",
       " 'ice age first comput gener featur cartoon feel like movi',\n",
       " 'ice age first comput gener featur cartoon feel like movi',\n",
       " 'ice age first comput gener featur cartoon feel like movi',\n",
       " 'ice age',\n",
       " 'ice',\n",
       " 'age',\n",
       " 'first comput gener featur cartoon feel like movi',\n",
       " 'first comput gener featur cartoon feel like movi',\n",
       " 'first comput gener featur cartoon',\n",
       " 'first comput gener featur cartoon',\n",
       " 'first',\n",
       " 'comput gener featur cartoon',\n",
       " 'comput gener',\n",
       " 'featur cartoon',\n",
       " 'featur',\n",
       " 'cartoon',\n",
       " 'feel like movi',\n",
       " 'feel like movi',\n",
       " 'feel',\n",
       " 'like movi',\n",
       " 'movi',\n",
       " '',\n",
       " 'make glacial pace earli',\n",
       " 'make glacial pace earli',\n",
       " 'make glacial pace',\n",
       " 'make',\n",
       " 'glacial pace',\n",
       " 'glacial pace',\n",
       " 'glacial pace',\n",
       " 'glacial',\n",
       " 'pace',\n",
       " 'earli',\n",
       " 'earli',\n",
       " 'littl sens go maker serv clich consider dash',\n",
       " 'littl sens go maker serv clich consider dash',\n",
       " 'littl sens go',\n",
       " 'littl sens go',\n",
       " 'littl sens go',\n",
       " 'littl sens go',\n",
       " 'littl sens go',\n",
       " 'littl sens',\n",
       " 'littl',\n",
       " 'go',\n",
       " 'go',\n",
       " 'go',\n",
       " 'go',\n",
       " 'go',\n",
       " '',\n",
       " 'maker serv clich consider dash',\n",
       " 'maker',\n",
       " 'maker',\n",
       " 'serv clich consider dash',\n",
       " 'serv',\n",
       " 'serv',\n",
       " 'clich consider dash',\n",
       " 'clich',\n",
       " 'clich',\n",
       " 'consider dash',\n",
       " 'consider dash',\n",
       " 'consider',\n",
       " 'dash',\n",
       " 'cattaneo follow runaway success first film full monti someth differ',\n",
       " 'cattaneo',\n",
       " 'follow runaway success first film full monti someth differ',\n",
       " 'follow runaway success first film full monti someth differ',\n",
       " 'follow runaway success first film full monti someth differ',\n",
       " 'follow runaway success first film full monti someth differ',\n",
       " 'follow runaway success first film full monti',\n",
       " 'follow',\n",
       " 'runaway success first film full monti',\n",
       " 'runaway success',\n",
       " 'runaway success',\n",
       " 'runaway',\n",
       " 'success',\n",
       " 'first film full monti',\n",
       " 'first film full monti',\n",
       " 'first film full monti',\n",
       " 'first film',\n",
       " 'first film',\n",
       " 'first film',\n",
       " 'full monti',\n",
       " 'full monti',\n",
       " 'full',\n",
       " 'monti',\n",
       " 'someth differ',\n",
       " 'someth differ',\n",
       " 'differ',\n",
       " 'unnam easili substitut forc serv whatev terror hero horror movi tri avoid',\n",
       " '',\n",
       " 'unnam easili substitut forc serv whatev terror hero horror movi tri avoid',\n",
       " 'unnam easili substitut forc serv whatev terror hero horror movi tri avoid',\n",
       " '',\n",
       " 'unnam easili substitut forc serv whatev terror hero horror movi tri avoid',\n",
       " 'unnam easili substitut forc',\n",
       " 'unnam easili substitut forc',\n",
       " 'unnam easili substitut',\n",
       " 'unnam',\n",
       " 'easili substitut',\n",
       " 'easili substitut',\n",
       " 'easili',\n",
       " 'substitut',\n",
       " 'forc',\n",
       " 'serv whatev terror hero horror movi tri avoid',\n",
       " 'serv whatev terror hero horror movi tri avoid',\n",
       " 'whatev terror hero horror movi tri avoid',\n",
       " 'whatev terror hero horror movi tri avoid',\n",
       " 'whatev',\n",
       " 'terror hero horror movi tri avoid',\n",
       " 'terror',\n",
       " 'hero horror movi tri avoid',\n",
       " 'hero horror movi',\n",
       " 'hero',\n",
       " 'hero',\n",
       " 'horror movi',\n",
       " 'horror movi',\n",
       " 'horror',\n",
       " 'tri avoid',\n",
       " ...]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KU9ujovQiT-X"
   },
   "source": [
    "### Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv = TfidfVectorizer(max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "heDukMA1iOVQ"
   },
   "outputs": [],
   "source": [
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "VbOjuKBxilWX"
   },
   "outputs": [],
   "source": [
    "# Saving BoW dictionary to later use in prediction\n",
    "import pickle\n",
    "bow_path = 'c1_BoW_Sentiment_Model.pkl'\n",
    "pickle.dump(cv, open(bow_path, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TMYMoQCioRX"
   },
   "source": [
    "### Dividing dataset into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "Oaqo1tU_io3N"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UvnwP9XisiZ"
   },
   "source": [
    "### Model fitting (GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "TemEGTQyit9i"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "SpOvD9fKiv2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c2_Classifier_Sentiment_Model']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exporting NB Classifier to later use in prediction\n",
    "import joblib\n",
    "joblib.dump(classifier, 'c2_Classifier_Sentiment_Model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27bV3J9wiyrd"
   },
   "source": [
    "### GaussianNB Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "eAqYjT4ciyAv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1184   69   12    7  144]\n",
      " [3380  549   96  121 1381]\n",
      " [5286  871  549  706 8227]\n",
      " [1156  180  108  494 4769]\n",
      " [ 111   18   11   89 1694]]\n",
      "0.1432141484044598\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.84      0.19      1416\n",
      "           1       0.33      0.10      0.15      5527\n",
      "           2       0.71      0.04      0.07     15639\n",
      "           3       0.35      0.07      0.12      6707\n",
      "           4       0.10      0.88      0.19      1923\n",
      "\n",
      "    accuracy                           0.14     31212\n",
      "   macro avg       0.32      0.39      0.14     31212\n",
      "weighted avg       0.50      0.14      0.11     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score , classification_report , confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test , y_pred))\n",
    "print(classification_report(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting (MultinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "gfQ8pWVpkdYt"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train , y_train)\n",
    "y_pred = mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "eT_J64UqksuV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5741701909521979\n",
      "[[   63   528   803    21     1]\n",
      " [   33  1096  4246   150     2]\n",
      " [    5   416 14504   704    10]\n",
      " [    1    62  4448  2142    54]\n",
      " [    0     3   810   994   116]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.04      0.08      1416\n",
      "           1       0.52      0.20      0.29      5527\n",
      "           2       0.58      0.93      0.72     15639\n",
      "           3       0.53      0.32      0.40      6707\n",
      "           4       0.63      0.06      0.11      1923\n",
      "\n",
      "    accuracy                           0.57     31212\n",
      "   macro avg       0.58      0.31      0.32     31212\n",
      "weighted avg       0.57      0.57      0.51     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test , y_pred))\n",
    "print(confusion_matrix(y_test , y_pred))\n",
    "print(classification_report(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT 3 Sentiment Analysis through OpenAI\n",
    "\n",
    "Reference:\n",
    "\n",
    "https://www.cronj.com/blog/impact-of-gpt-3-on-text-classification-sentiment-analysis/\n",
    "\n",
    "https://www.width.ai/post/twitter-sentiment-analysis-using-gpt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"Your_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentiment_prompt(text):\n",
    "\n",
    "    return f\"Please analyze the sentiment of the following text and classify each line as 0 - negative, 1 - somewhat negative, 2 - neutral, 3 - somewhat positive, 4 - positive and \\\n",
    "    return in an array format, : \\n {text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "\n",
    "    prompt = create_sentiment_prompt(text)\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "\n",
    "        engine=\"text-davinci-003\",\n",
    "\n",
    "        prompt=prompt,\n",
    "\n",
    "        max_tokens=1024,\n",
    "\n",
    "        n=1,\n",
    "\n",
    "        stop=None,\n",
    "\n",
    "        temperature=0.1,\n",
    "\n",
    "    )\n",
    "\n",
    "    sentiment = response.choices[0].text.strip()\n",
    "\n",
    "\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.Phrase\n",
    "y = df.Sentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "\n",
    "# due to free API key only can call 60 times epr minutes, we call 60 times, each time classifying 20 phrases, total 1200 values\n",
    "for i in range(61):\n",
    "    sentiment_result = analyze_sentiment(X_test[i:i+21])\n",
    "    y_pred.extend(list(sentiment_result.replace(', ', '').replace('[', '').replace(']', '').replace(',', '').strip()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pred = list(map(int, y_pred))\n",
    "print(f\"Sentiment: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7   6  11   8  14]\n",
      " [ 40  22  47  49  37]\n",
      " [ 95  49 134  98 138]\n",
      " [ 33  22  57  43  51]\n",
      " [  7   4  23  12  12]]\n",
      "0.2139352306182532\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.15      0.06        46\n",
      "           1       0.21      0.11      0.15       195\n",
      "           2       0.49      0.26      0.34       514\n",
      "           3       0.20      0.21      0.21       206\n",
      "           4       0.05      0.21      0.08        58\n",
      "\n",
      "    accuracy                           0.21      1019\n",
      "   macro avg       0.20      0.19      0.17      1019\n",
      "weighted avg       0.34      0.21      0.25      1019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GPT 3 sometimes can ignore a small amount of inputs and do not output prediction, so the final y_pred is not 1200 exactly \n",
    "cm = confusion_matrix(y_test[0: 1019], y_pred)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test[0: 1019] , y_pred))\n",
    "print(classification_report(y_test[0: 1019] , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
